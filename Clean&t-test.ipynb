{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined and cleaned data has been saved in 'combined_cleaned_prices.xlsx' under the sheet 'Prices'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the 'Price' columns from both Excel files\n",
    "file_path1 = 'Australia_market_1.xlsx'\n",
    "file_path2 = 'stock_prices_2024_09_30.xlsx'\n",
    "df1 = pd.read_excel(file_path1)[['Price']].rename(columns={'Price': 'Price_1'})\n",
    "df2 = pd.read_excel(file_path2)[['Price']].rename(columns={'Price': 'Price_2'})\n",
    "\n",
    "# Combine the two DataFrames into a single DataFrame with both 'Price_1' and 'Price_2' columns\n",
    "df_combined = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# Drop rows where 'Price_2' has null values\n",
    "df_cleaned = df_combined.dropna(subset=['Price_2'])\n",
    "\n",
    "# Save the cleaned data to a new Excel file with the sheet name \"Prices\"\n",
    "output_path = 'combined_cleaned_prices.xlsx'\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    df_cleaned.to_excel(writer, sheet_name='Prices', index=False)\n",
    "\n",
    "print(f\"The combined and cleaned data has been saved in '{output_path}' under the sheet 'Prices'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been saved as 'portfolio_prices.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined_cleaned_prices.xlsx file\n",
    "df_combined = pd.read_excel('combined_cleaned_prices.xlsx', sheet_name='Prices')\n",
    "\n",
    "# Save it as a CSV file\n",
    "df_combined.to_csv('portfolio_prices.csv', index=False)\n",
    "\n",
    "print(\"The file has been saved as 'portfolio_prices.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Sample T-Test Results at 95% Confidence Level:\n",
      "Portfolio Average Simple Return = 0.0964\n",
      "Portfolio Average Log Return = 0.0095\n",
      "Market Simple Return = 0.0498\n",
      "Market Log Return = 0.0486\n",
      "Simple Return vs Market Return: T-Statistic = 1.3964, P-Value = 0.1647\n",
      "Log Return vs Market Return: T-Statistic = -0.9422, P-Value = 0.3476\n",
      "Fail to reject the null hypothesis for Simple Return: Portfolio does not outperform the market.\n",
      "Fail to reject the null hypothesis for Log Return: Portfolio does not outperform the market.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "import yfinance as yf\n",
    "\n",
    "# Step 1: Load Portfolio Data\n",
    "portfolio_prices = pd.read_csv('portfolio_prices.csv')  # Assuming first column is June 6 prices and second column is Sept 30 prices\n",
    "portfolio_prices.columns = ['Price_1', 'Price_2']\n",
    "\n",
    "# Step 2: Calculate Simple and Log Returns for Each Stock in the Portfolio\n",
    "portfolio_prices['Simple_Return'] = (portfolio_prices['Price_2'] - portfolio_prices['Price_1']) / portfolio_prices['Price_1']\n",
    "portfolio_prices['Log_Return'] = np.log(portfolio_prices['Price_2'] / portfolio_prices['Price_1'])\n",
    "\n",
    "# Since the portfolio is equally weighted, calculate the average returns\n",
    "average_simple_return = portfolio_prices['Simple_Return'].mean()\n",
    "average_log_return = portfolio_prices['Log_Return'].mean()\n",
    "\n",
    "# Step 3: Download Market Data for ^AORD and calculate returns over the period\n",
    "stock_code = \"^AORD\"\n",
    "start_date = \"2024-06-06\"\n",
    "end_date = \"2024-09-30\"\n",
    "\n",
    "# Download the market data\n",
    "market_data = yf.download(stock_code, start=start_date, end=end_date)\n",
    "\n",
    "# Calculate the market's simple and log return from June 6 to September 30\n",
    "market_start_price = market_data['Close'].iloc[0]  # First available closing price on or after June 6\n",
    "market_end_price = market_data['Close'].iloc[-1]  # Last available closing price on or before September 30\n",
    "market_simple_return = (market_end_price - market_start_price) / market_start_price\n",
    "market_log_return = np.log(market_end_price / market_start_price)\n",
    "\n",
    "# Step 4: Perform One-Sample T-Tests for Simple and Log Returns against the market return\n",
    "alpha = 0.05  # 95% confidence level\n",
    "\n",
    "# T-test for Simple Return\n",
    "simple_t_stat, simple_p_value = ttest_1samp(portfolio_prices['Simple_Return'], market_simple_return)\n",
    "\n",
    "# T-test for Log Return\n",
    "log_t_stat, log_p_value = ttest_1samp(portfolio_prices['Log_Return'], market_log_return)\n",
    "\n",
    "# Print Results\n",
    "print(\"One-Sample T-Test Results at 95% Confidence Level:\")\n",
    "print(f\"Portfolio Average Simple Return = {average_simple_return:.4f}\")\n",
    "print(f\"Portfolio Average Log Return = {average_log_return:.4f}\")\n",
    "print(f\"Market Simple Return = {market_simple_return:.4f}\")\n",
    "print(f\"Market Log Return = {market_log_return:.4f}\")\n",
    "\n",
    "print(f\"Simple Return vs Market Return: T-Statistic = {simple_t_stat:.4f}, P-Value = {simple_p_value:.4f}\")\n",
    "print(f\"Log Return vs Market Return: T-Statistic = {log_t_stat:.4f}, P-Value = {log_p_value:.4f}\")\n",
    "\n",
    "if simple_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Simple Return: Portfolio outperforms the market.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Simple Return: Portfolio does not outperform the market.\")\n",
    "\n",
    "if log_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Log Return: Portfolio outperforms the market.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Log Return: Portfolio does not outperform the market.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['ALU.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BLD.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AWC.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['CSR.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['ABC.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SLR.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MRM.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['TIE.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GNX.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['QIP.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BIX.AX']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2024-06-06 -> 2024-09-30)')\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MEA.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PGL.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['DCG.AX']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'portfolio_daily_prices.csv' has been created with daily closing prices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/kq/1c1dzqtj4b7_9p_ygqzc4nfw0000gn/T/ipykernel_91342/3685174830.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  portfolio_daily_prices[ticker] = data['Close']\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Load the stock list from the Excel file\n",
    "stock_file_path = 'stock_prices_2024_09_30.xlsx'\n",
    "stock_data = pd.read_excel(stock_file_path)\n",
    "your_stock_list = stock_data['Code'].dropna().unique().tolist()  # Extract unique stock codes\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = \"2024-06-06\"\n",
    "end_date = \"2024-09-30\"\n",
    "\n",
    "# Create an empty DataFrame to store the closing prices\n",
    "portfolio_daily_prices = pd.DataFrame()\n",
    "\n",
    "# Download and collect daily closing prices for each stock\n",
    "for ticker in your_stock_list:\n",
    "    # Download the stock data\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    \n",
    "    # Add the 'Close' column to the portfolio DataFrame, using the ticker as the column name\n",
    "    portfolio_daily_prices[ticker] = data['Close']\n",
    "\n",
    "# Save the daily prices to a CSV file\n",
    "portfolio_daily_prices.to_csv('portfolio_daily_prices.csv')\n",
    "\n",
    "print(\"The file 'portfolio_daily_prices.csv' has been created with daily closing prices.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cleaned file 'portfolio_daily_prices_cleaned.csv' has been saved, with all stocks containing null values removed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the portfolio daily prices data\n",
    "file_path = 'portfolio_daily_prices.csv'\n",
    "portfolio_prices = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "\n",
    "# Drop columns (stocks) with any null values\n",
    "portfolio_prices_cleaned = portfolio_prices.dropna(axis=1)\n",
    "\n",
    "# Save the cleaned data back to CSV\n",
    "portfolio_prices_cleaned.to_csv('portfolio_daily_prices.csv')\n",
    "\n",
    "print(\"The cleaned file 'portfolio_daily_prices_cleaned.csv' has been saved, with all stocks containing null values removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Sample T-Test Results at 95% Confidence Level:\n",
      "Average Daily Portfolio Simple Return = 0.0016\n",
      "Average Daily Market Simple Return = 0.0006\n",
      "Simple Return vs Market Return: T-Statistic = 0.8731, P-Value = 0.3853\n",
      "Fail to reject the null hypothesis for Daily Simple Return: Portfolio does not outperform the market.\n",
      "\n",
      "\n",
      "Average Daily Portfolio Log Return = 0.0003\n",
      "Average Daily Market Log Return = 0.0005\n",
      "Log Return vs Market Return: T-Statistic = -0.2310, P-Value = 0.8180\n",
      "Fail to reject the null hypothesis for Daily Log Return: Portfolio does not outperform the market.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "import yfinance as yf\n",
    "\n",
    "# Step 1: Load Daily Portfolio Data\n",
    "# Assuming 'portfolio_daily_prices.csv' has dates as index and each stock's prices as columns\n",
    "portfolio_daily_prices = pd.read_csv('portfolio_daily_prices.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Step 2: Calculate Daily Simple and Log Returns for Each Stock\n",
    "# Simple return: (P_t - P_(t-1)) / P_(t-1)\n",
    "daily_simple_returns = portfolio_daily_prices.pct_change().dropna()\n",
    "\n",
    "# Log return: log(P_t / P_(t-1))\n",
    "daily_log_returns = np.log(portfolio_daily_prices / portfolio_daily_prices.shift(1)).dropna()\n",
    "\n",
    "# Calculate the daily portfolio return by averaging the daily returns across all stocks\n",
    "# (equally weighted)\n",
    "daily_portfolio_simple_return = daily_simple_returns.mean(axis=1)\n",
    "daily_portfolio_log_return = daily_log_returns.mean(axis=1)\n",
    "\n",
    "# Step 3: Download Market Daily Data for ^AORD over the same period\n",
    "stock_code = \"^AORD\"\n",
    "start_date = daily_portfolio_simple_return.index.min().strftime('%Y-%m-%d')\n",
    "end_date = daily_portfolio_simple_return.index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "# Download the market data\n",
    "market_data = yf.download(stock_code, start=start_date, end=end_date)\n",
    "\n",
    "# Calculate the market's daily simple and log returns\n",
    "market_daily_simple_return = market_data['Close'].pct_change().dropna()\n",
    "market_daily_log_return = np.log(market_data['Close'] / market_data['Close'].shift(1)).dropna()\n",
    "\n",
    "# Step 4: Align Portfolio and Market Returns by Date\n",
    "aligned_simple_portfolio_return, aligned_simple_market_return = daily_portfolio_simple_return.align(market_daily_simple_return, join='inner')\n",
    "aligned_log_portfolio_return, aligned_log_market_return = daily_portfolio_log_return.align(market_daily_log_return, join='inner')\n",
    "\n",
    "# Step 5: Perform One-Sample T-Tests for Daily Simple and Log Returns against the market daily return\n",
    "alpha = 0.05  # 95% confidence level\n",
    "\n",
    "# T-test for Daily Simple Returns\n",
    "simple_t_stat, simple_p_value = ttest_1samp(aligned_simple_portfolio_return, aligned_simple_market_return.mean())\n",
    "\n",
    "# T-test for Daily Log Returns\n",
    "log_t_stat, log_p_value = ttest_1samp(aligned_log_portfolio_return, aligned_log_market_return.mean())\n",
    "\n",
    "# Print Results\n",
    "print(\"One-Sample T-Test Results at 95% Confidence Level:\")\n",
    "print(f\"Average Daily Portfolio Simple Return = {aligned_simple_portfolio_return.mean():.4f}\")\n",
    "print(f\"Average Daily Market Simple Return = {aligned_simple_market_return.mean():.4f}\")\n",
    "print(f\"Simple Return vs Market Return: T-Statistic = {simple_t_stat:.4f}, P-Value = {simple_p_value:.4f}\")\n",
    "\n",
    "if simple_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Daily Simple Return: Portfolio outperforms the market.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Daily Simple Return: Portfolio does not outperform the market.\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Average Daily Portfolio Log Return = {aligned_log_portfolio_return.mean():.4f}\")\n",
    "print(f\"Average Daily Market Log Return = {aligned_log_market_return.mean():.4f}\")\n",
    "print(f\"Log Return vs Market Return: T-Statistic = {log_t_stat:.4f}, P-Value = {log_p_value:.4f}\")\n",
    "\n",
    "if log_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Daily Log Return: Portfolio outperforms the market.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Daily Log Return: Portfolio does not outperform the market.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2024-06-07, End date: 2024-09-27\n",
      "T-statistic: 0.873129814022225, P-value: 0.3853071263429737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Assuming 'portfolio_daily_prices_cleaned.csv' is the cleaned file without null columns\n",
    "portfolio_prices = pd.read_csv('portfolio_daily_prices_cleaned.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Check if the DataFrame is empty\n",
    "if portfolio_prices.empty:\n",
    "    raise ValueError(\"The portfolio data is empty after cleaning.\")\n",
    "\n",
    "# Step 1: Calculate daily simple returns\n",
    "daily_simple_returns = portfolio_prices.pct_change().dropna()\n",
    "\n",
    "# Step 2: Check if the date index is valid and extract date range\n",
    "if daily_simple_returns.index.isnull().any():\n",
    "    raise ValueError(\"Invalid date index in portfolio data.\")\n",
    "\n",
    "start_date = daily_simple_returns.index.min().strftime('%Y-%m-%d')\n",
    "end_date = daily_simple_returns.index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Start date: {start_date}, End date: {end_date}\")\n",
    "\n",
    "# Step 3: Download Market Daily Data for ^AORD\n",
    "stock_code = \"^AORD\"\n",
    "market_data = yf.download(stock_code, start=start_date, end=end_date)\n",
    "\n",
    "# Calculate market daily returns\n",
    "market_daily_returns = market_data['Close'].pct_change().dropna()\n",
    "\n",
    "# Now you can perform further analysis with daily returns\n",
    "# Example: Align and compare daily returns for t-test\n",
    "aligned_portfolio_return, aligned_market_return = daily_simple_returns.mean(axis=1).align(market_daily_returns, join='inner')\n",
    "\n",
    "# T-test example\n",
    "t_stat, p_value = ttest_1samp(aligned_portfolio_return, aligned_market_return.mean())\n",
    "\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Sample T-Test Results at 95% Confidence Level:\n",
      "Average Daily Portfolio Return = 0.0016\n",
      "Average Daily Market Return = 0.0006\n",
      "T-Statistic = 0.8731, P-Value = 0.3853\n",
      "Fail to reject the null hypothesis: Portfolio daily returns are not significantly different from the market's daily returns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "import yfinance as yf\n",
    "\n",
    "# Step 1: Load and Clean Portfolio Daily Prices Data\n",
    "portfolio_prices = pd.read_csv('portfolio_daily_prices_cleaned.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Step 2: Calculate Daily Simple Returns for Each Stock\n",
    "daily_simple_returns = portfolio_prices.pct_change().dropna()\n",
    "\n",
    "# Step 3: Determine Start and End Dates from the Data\n",
    "start_date = daily_simple_returns.index.min().strftime('%Y-%m-%d')\n",
    "end_date = daily_simple_returns.index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "# Step 4: Download Market Daily Data for ^AORD\n",
    "stock_code = \"^AORD\"\n",
    "market_data = yf.download(stock_code, start=start_date, end=end_date)\n",
    "\n",
    "# Step 5: Calculate Market Daily Returns\n",
    "market_daily_returns = market_data['Close'].pct_change().dropna()\n",
    "\n",
    "# Step 6: Calculate Portfolio's Average Daily Return (equally weighted)\n",
    "daily_portfolio_return = daily_simple_returns.mean(axis=1)\n",
    "\n",
    "# Align Portfolio and Market Returns by Date\n",
    "aligned_portfolio_return, aligned_market_return = daily_portfolio_return.align(market_daily_returns, join='inner')\n",
    "\n",
    "# Step 7: Perform One-Sample T-Test\n",
    "alpha = 0.05  # 95% confidence level\n",
    "\n",
    "# Calculate t-statistic and p-value\n",
    "t_stat, p_value = ttest_1samp(aligned_portfolio_return, aligned_market_return.mean())\n",
    "\n",
    "# Step 8: Print Results\n",
    "print(\"One-Sample T-Test Results at 95% Confidence Level:\")\n",
    "print(f\"Average Daily Portfolio Return = {aligned_portfolio_return.mean():.4f}\")\n",
    "print(f\"Average Daily Market Return = {aligned_market_return.mean():.4f}\")\n",
    "print(f\"T-Statistic = {t_stat:.4f}, P-Value = {p_value:.4f}\")\n",
    "\n",
    "# Determine if portfolio outperforms the market\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: Portfolio daily returns are significantly different from the market's daily returns.\")\n",
    "    if aligned_portfolio_return.mean() > aligned_market_return.mean():\n",
    "        print(\"The portfolio outperforms the market.\")\n",
    "    else:\n",
    "        print(\"The portfolio underperforms compared to the market.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: Portfolio daily returns are not significantly different from the market's daily returns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Sample T-Test Results at 95% Confidence Level:\n",
      "\n",
      "Simple Returns:\n",
      "Average Daily Portfolio Simple Return = 0.0016\n",
      "Average Daily Market Simple Return = 0.0006\n",
      "Simple Return T-Statistic = 0.8731, P-Value = 0.3853\n",
      "Fail to reject the null hypothesis for Simple Returns: Portfolio daily simple returns are not significantly different from the market's.\n",
      "\n",
      "Log Returns:\n",
      "Average Daily Portfolio Log Return = 0.0003\n",
      "Average Daily Market Log Return = 0.0005\n",
      "Log Return T-Statistic = -0.2310, P-Value = 0.8180\n",
      "Fail to reject the null hypothesis for Log Returns: Portfolio daily log returns are not significantly different from the market's.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "import yfinance as yf\n",
    "\n",
    "# Step 1: Load and Clean Portfolio Daily Prices Data\n",
    "portfolio_prices = pd.read_csv('portfolio_daily_prices_cleaned.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Step 2: Calculate Daily Simple and Log Returns for Each Stock\n",
    "# Simple Return: (P_t - P_(t-1)) / P_(t-1)\n",
    "daily_simple_returns = portfolio_prices.pct_change().dropna()\n",
    "\n",
    "# Log Return: log(P_t / P_(t-1))\n",
    "daily_log_returns = np.log(portfolio_prices / portfolio_prices.shift(1)).dropna()\n",
    "\n",
    "# Step 3: Determine Start and End Dates from the Data\n",
    "start_date = daily_simple_returns.index.min().strftime('%Y-%m-%d')\n",
    "end_date = daily_simple_returns.index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "# Step 4: Download Market Daily Data for ^AORD\n",
    "stock_code = \"^AORD\"\n",
    "market_data = yf.download(stock_code, start=start_date, end=end_date)\n",
    "\n",
    "# Step 5: Calculate Market Daily Simple and Log Returns\n",
    "market_daily_simple_return = market_data['Close'].pct_change().dropna()\n",
    "market_daily_log_return = np.log(market_data['Close'] / market_data['Close'].shift(1)).dropna()\n",
    "\n",
    "# Step 6: Calculate Portfolio's Average Daily Returns (equally weighted)\n",
    "# Daily portfolio return is the mean across all stocks for each day\n",
    "daily_portfolio_simple_return = daily_simple_returns.mean(axis=1)\n",
    "daily_portfolio_log_return = daily_log_returns.mean(axis=1)\n",
    "\n",
    "# Align Portfolio and Market Returns by Date\n",
    "aligned_simple_portfolio_return, aligned_simple_market_return = daily_portfolio_simple_return.align(market_daily_simple_return, join='inner')\n",
    "aligned_log_portfolio_return, aligned_log_market_return = daily_portfolio_log_return.align(market_daily_log_return, join='inner')\n",
    "\n",
    "# Step 7: Perform One-Sample T-Tests for Simple and Log Returns\n",
    "alpha = 0.05  # 95% confidence level\n",
    "\n",
    "# T-test for Daily Simple Returns\n",
    "simple_t_stat, simple_p_value = ttest_1samp(aligned_simple_portfolio_return, aligned_simple_market_return.mean())\n",
    "\n",
    "# T-test for Daily Log Returns\n",
    "log_t_stat, log_p_value = ttest_1samp(aligned_log_portfolio_return, aligned_log_market_return.mean())\n",
    "\n",
    "# Step 8: Print Results\n",
    "print(\"One-Sample T-Test Results at 95% Confidence Level:\")\n",
    "print(f\"\\nSimple Returns:\")\n",
    "print(f\"Average Daily Portfolio Simple Return = {aligned_simple_portfolio_return.mean():.4f}\")\n",
    "print(f\"Average Daily Market Simple Return = {aligned_simple_market_return.mean():.4f}\")\n",
    "print(f\"Simple Return T-Statistic = {simple_t_stat:.4f}, P-Value = {simple_p_value:.4f}\")\n",
    "\n",
    "if simple_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Simple Returns: Portfolio daily simple returns are significantly different from the market's.\")\n",
    "    if aligned_simple_portfolio_return.mean() > aligned_simple_market_return.mean():\n",
    "        print(\"The portfolio outperforms the market in terms of daily simple returns.\")\n",
    "    else:\n",
    "        print(\"The portfolio underperforms compared to the market in terms of daily simple returns.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Simple Returns: Portfolio daily simple returns are not significantly different from the market's.\")\n",
    "\n",
    "print(f\"\\nLog Returns:\")\n",
    "print(f\"Average Daily Portfolio Log Return = {aligned_log_portfolio_return.mean():.4f}\")\n",
    "print(f\"Average Daily Market Log Return = {aligned_log_market_return.mean():.4f}\")\n",
    "print(f\"Log Return T-Statistic = {log_t_stat:.4f}, P-Value = {log_p_value:.4f}\")\n",
    "\n",
    "if log_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Log Returns: Portfolio daily log returns are significantly different from the market's.\")\n",
    "    if aligned_log_portfolio_return.mean() > aligned_log_market_return.mean():\n",
    "        print(\"The portfolio outperforms the market in terms of daily log returns.\")\n",
    "    else:\n",
    "        print(\"The portfolio underperforms compared to the market in terms of daily log returns.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Log Returns: Portfolio daily log returns are not significantly different from the market's.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Sample T-Test Results at 95% Confidence Level (Cumulative Returns):\n",
      "\n",
      "Cumulative Simple Returns:\n",
      "Average Cumulative Portfolio Simple Return = 0.0964\n",
      "Market Cumulative Simple Return = 0.0498\n",
      "Simple Return T-Statistic = 1.3964, P-Value = 0.1647\n",
      "Fail to reject the null hypothesis for Cumulative Simple Returns: Portfolio cumulative simple returns are not significantly different from the market's.\n",
      "\n",
      "Cumulative Log Returns:\n",
      "Average Cumulative Portfolio Log Return = 0.0095\n",
      "Market Cumulative Log Return = 0.0486\n",
      "Log Return T-Statistic = -0.9422, P-Value = 0.3476\n",
      "Fail to reject the null hypothesis for Cumulative Log Returns: Portfolio cumulative log returns are not significantly different from the market's.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "import yfinance as yf\n",
    "\n",
    "# Step 1: Load Portfolio Prices on June 6 and September 30\n",
    "# Assuming 'portfolio_prices.csv' has June 6 prices in 'Price_1' column and Sept 30 prices in 'Price_2' column\n",
    "portfolio_prices = pd.read_csv('portfolio_prices.csv')\n",
    "portfolio_prices.columns = ['Price_1', 'Price_2']\n",
    "\n",
    "# Step 2: Calculate Cumulative Simple and Log Returns for Each Stock\n",
    "portfolio_prices['Cumulative_Simple_Return'] = (portfolio_prices['Price_2'] - portfolio_prices['Price_1']) / portfolio_prices['Price_1']\n",
    "portfolio_prices['Cumulative_Log_Return'] = np.log(portfolio_prices['Price_2'] / portfolio_prices['Price_1'])\n",
    "\n",
    "# Calculate the average cumulative simple and log returns across all stocks (equally weighted)\n",
    "average_cumulative_simple_return = portfolio_prices['Cumulative_Simple_Return'].mean()\n",
    "average_cumulative_log_return = portfolio_prices['Cumulative_Log_Return'].mean()\n",
    "\n",
    "# Step 3: Download Market Data for ^AORD and calculate cumulative return from June 6 to September 30\n",
    "stock_code = \"^AORD\"\n",
    "start_date = \"2024-06-06\"\n",
    "end_date = \"2024-09-30\"\n",
    "\n",
    "# Download the market data\n",
    "market_data = yf.download(stock_code, start=start_date, end=end_date)\n",
    "\n",
    "# Calculate the market's cumulative simple and log return\n",
    "market_start_price = market_data['Close'].iloc[0]\n",
    "market_end_price = market_data['Close'].iloc[-1]\n",
    "market_cumulative_simple_return = (market_end_price - market_start_price) / market_start_price\n",
    "market_cumulative_log_return = np.log(market_end_price / market_start_price)\n",
    "\n",
    "# Step 4: Perform One-Sample T-Tests for Cumulative Simple and Log Returns\n",
    "alpha = 0.05  # 95% confidence level\n",
    "\n",
    "# T-test for Cumulative Simple Return\n",
    "simple_t_stat, simple_p_value = ttest_1samp(portfolio_prices['Cumulative_Simple_Return'], market_cumulative_simple_return)\n",
    "\n",
    "# T-test for Cumulative Log Return\n",
    "log_t_stat, log_p_value = ttest_1samp(portfolio_prices['Cumulative_Log_Return'], market_cumulative_log_return)\n",
    "\n",
    "# Step 5: Print Results\n",
    "print(\"One-Sample T-Test Results at 95% Confidence Level (Cumulative Returns):\")\n",
    "print(f\"\\nCumulative Simple Returns:\")\n",
    "print(f\"Average Cumulative Portfolio Simple Return = {average_cumulative_simple_return:.4f}\")\n",
    "print(f\"Market Cumulative Simple Return = {market_cumulative_simple_return:.4f}\")\n",
    "print(f\"Simple Return T-Statistic = {simple_t_stat:.4f}, P-Value = {simple_p_value:.4f}\")\n",
    "\n",
    "if simple_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Cumulative Simple Returns: Portfolio cumulative simple returns are significantly different from the market's.\")\n",
    "    if average_cumulative_simple_return > market_cumulative_simple_return:\n",
    "        print(\"The portfolio outperforms the market in terms of cumulative simple returns.\")\n",
    "    else:\n",
    "        print(\"The portfolio underperforms compared to the market in terms of cumulative simple returns.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Cumulative Simple Returns: Portfolio cumulative simple returns are not significantly different from the market's.\")\n",
    "\n",
    "print(f\"\\nCumulative Log Returns:\")\n",
    "print(f\"Average Cumulative Portfolio Log Return = {average_cumulative_log_return:.4f}\")\n",
    "print(f\"Market Cumulative Log Return = {market_cumulative_log_return:.4f}\")\n",
    "print(f\"Log Return T-Statistic = {log_t_stat:.4f}, P-Value = {log_p_value:.4f}\")\n",
    "\n",
    "if log_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Cumulative Log Returns: Portfolio cumulative log returns are significantly different from the market's.\")\n",
    "    if average_cumulative_log_return > market_cumulative_log_return:\n",
    "        print(\"The portfolio outperforms the market in terms of cumulative log returns.\")\n",
    "    else:\n",
    "        print(\"The portfolio underperforms compared to the market in terms of cumulative log returns.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Cumulative Log Returns: Portfolio cumulative log returns are not significantly different from the market's.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Sample T-Test Results at 95% Confidence Level (Daily Returns):\n",
      "\n",
      "Daily Simple Returns:\n",
      "Average Daily Portfolio Simple Return = 0.0001\n",
      "Market Daily Simple Return = 0.0006\n",
      "Simple Return T-Statistic = -0.9170, P-Value = 0.3606\n",
      "Fail to reject the null hypothesis for Daily Simple Returns: Portfolio daily simple returns are not significantly different from the market's.\n",
      "\n",
      "Daily Log Returns:\n",
      "Average Daily Portfolio Log Return = 0.0001\n",
      "Market Daily Log Return = 0.0006\n",
      "Log Return T-Statistic = -0.9422, P-Value = 0.3476\n",
      "Fail to reject the null hypothesis for Daily Log Returns: Portfolio daily log returns are not significantly different from the market's.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "import yfinance as yf\n",
    "\n",
    "# Load Portfolio Prices on June 6 and September 30\n",
    "portfolio_prices = pd.read_csv('portfolio_prices.csv')\n",
    "portfolio_prices.columns = ['Price_1', 'Price_2']\n",
    "\n",
    "# Calculate Cumulative Simple and Log Returns for Each Stock\n",
    "portfolio_prices['Cumulative_Simple_Return'] = (portfolio_prices['Price_2'] - portfolio_prices['Price_1']) / portfolio_prices['Price_1']\n",
    "portfolio_prices['Cumulative_Log_Return'] = np.log(portfolio_prices['Price_2'] / portfolio_prices['Price_1'])\n",
    "\n",
    "# Number of days from June 6 to September 30\n",
    "num_days = 82\n",
    "\n",
    "# Calculate the average daily simple and log returns for the portfolio\n",
    "portfolio_prices['Daily_Simple_Return'] = (1 + portfolio_prices['Cumulative_Simple_Return'])**(1 / num_days) - 1\n",
    "portfolio_prices['Daily_Log_Return'] = portfolio_prices['Cumulative_Log_Return'] / num_days\n",
    "\n",
    "# Calculate the average daily simple and log returns across all stocks (equally weighted)\n",
    "average_daily_simple_return = portfolio_prices['Daily_Simple_Return'].mean()\n",
    "average_daily_log_return = portfolio_prices['Daily_Log_Return'].mean()\n",
    "\n",
    "# Download Market Data for ^AORD and calculate cumulative return\n",
    "stock_code = \"^AORD\"\n",
    "start_date = \"2024-06-06\"\n",
    "end_date = \"2024-09-30\"\n",
    "market_data = yf.download(stock_code, start=start_date, end=end_date)\n",
    "\n",
    "# Market cumulative simple and log returns\n",
    "market_start_price = market_data['Close'].iloc[0]\n",
    "market_end_price = market_data['Close'].iloc[-1]\n",
    "market_cumulative_simple_return = (market_end_price - market_start_price) / market_start_price\n",
    "market_cumulative_log_return = np.log(market_end_price / market_start_price)\n",
    "\n",
    "# Calculate the market's daily simple and log returns\n",
    "market_daily_simple_return = (1 + market_cumulative_simple_return)**(1 / num_days) - 1\n",
    "market_daily_log_return = market_cumulative_log_return / num_days\n",
    "\n",
    "# Perform T-tests\n",
    "alpha = 0.05  # 95% confidence level\n",
    "\n",
    "# T-test for Daily Simple Returns\n",
    "simple_t_stat, simple_p_value = ttest_1samp(portfolio_prices['Daily_Simple_Return'], market_daily_simple_return)\n",
    "\n",
    "# T-test for Daily Log Returns\n",
    "log_t_stat, log_p_value = ttest_1samp(portfolio_prices['Daily_Log_Return'], market_daily_log_return)\n",
    "\n",
    "# Print Results\n",
    "print(\"One-Sample T-Test Results at 95% Confidence Level (Daily Returns):\")\n",
    "print(f\"\\nDaily Simple Returns:\")\n",
    "print(f\"Average Daily Portfolio Simple Return = {average_daily_simple_return:.4f}\")\n",
    "print(f\"Market Daily Simple Return = {market_daily_simple_return:.4f}\")\n",
    "print(f\"Simple Return T-Statistic = {simple_t_stat:.4f}, P-Value = {simple_p_value:.4f}\")\n",
    "\n",
    "if simple_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Daily Simple Returns: Portfolio daily simple returns are significantly different from the market's.\")\n",
    "    if average_daily_simple_return > market_daily_simple_return:\n",
    "        print(\"The portfolio outperforms the market in terms of daily simple returns.\")\n",
    "    else:\n",
    "        print(\"The portfolio underperforms compared to the market in terms of daily simple returns.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Daily Simple Returns: Portfolio daily simple returns are not significantly different from the market's.\")\n",
    "\n",
    "print(f\"\\nDaily Log Returns:\")\n",
    "print(f\"Average Daily Portfolio Log Return = {average_daily_log_return:.4f}\")\n",
    "print(f\"Market Daily Log Return = {market_daily_log_return:.4f}\")\n",
    "print(f\"Log Return T-Statistic = {log_t_stat:.4f}, P-Value = {log_p_value:.4f}\")\n",
    "\n",
    "if log_p_value < alpha:\n",
    "    print(\"Reject the null hypothesis for Daily Log Returns: Portfolio daily log returns are significantly different from the market's.\")\n",
    "    if average_daily_log_return > market_daily_log_return:\n",
    "        print(\"The portfolio outperforms the market in terms of daily log returns.\")\n",
    "    else:\n",
    "        print(\"The portfolio underperforms compared to the market in terms of daily log returns.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for Daily Log Returns: Portfolio daily log returns are not significantly different from the market's.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
